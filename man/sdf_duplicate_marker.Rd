% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sdf_duplicate_marker.R
\name{sdf_duplicate_marker}
\alias{sdf_duplicate_marker}
\title{This method will flag any duplicate records}
\usage{
sdf_duplicate_marker(sc, data, part_col, ord_col,
  new_column_name = "duplicate")
}
\arguments{
\item{sc}{A \code{spark_connection}.}

\item{data}{A \code{jobj}: the Spark \code{DataFrame} on which to perform the
function.}

\item{part_col}{String(s). A vector of the column(s) to check for duplicates
within.}

\item{ord_col}{String(s). A list of the column(s) to order by.}

\item{new_column_name}{A string. This is what the duplicate marker column is
called, it can be defaulted to "duplicate".}
}
\value{
Returns a \code{jobj}.
* 0 = Duplicate
* 1 = Not a Duplicate
}
\description{
This method adds a column to a dataframe containing duplicate markers.
}
\examples{
\dontrun{
# Set up a spark connection
sc <- spark_connect(master = "local", version = "2.2.0")

# Extract some data
dup_data <- spark_read_json(
  sc,
  "std_data",
  path = system.file(
    "data_raw/DuplicateDataIn.json",
    package = "sparkts"
  )
) \%>\%
  spark_dataframe()

# Call the method
p <- sdf_duplicate_marker(
  sc, dup_data, part_col = "order", ord_col = "marker"
)

# Return the data to R
p \%>\% dplyr::collect()

spark_disconnect(sc = sc)
}

}
